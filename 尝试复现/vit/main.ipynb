{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面这一段是在autodl的gpu上进行下载cat-and-dog数据集的代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ini"
    }
   },
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import shutil\n",
    "import os\n",
    "# 指定下载路径\n",
    "\n",
    "\n",
    "# 下载数据集\n",
    "path = kagglehub.dataset_download(\"marquis03/cats-and-dogs\")\n",
    "\n",
    "\n",
    "download_path = \"/root/autodl-tmp\"\n",
    "os.makedirs(download_path, exist_ok=True)\n",
    "\n",
    "# 移动数据集到目标路径\n",
    "shutil.move(path, download_path)\n",
    "\n",
    "print(f\"Dataset moved to: {download_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ini"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import glob\n",
    "from itertools import chain\n",
    "import os\n",
    "import random\n",
    "import zipfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from linformer import Linformer\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from module import ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ini"
    }
   },
   "outputs": [],
   "source": [
    "# Training settings\n",
    "batch_size = 64\n",
    "epochs = 20\n",
    "lr = 3e-5\n",
    "gamma = 0.7\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ini"
    }
   },
   "outputs": [],
   "source": [
    "model = ViT(\n",
    "    dim=128,\n",
    "    image_size=224,\n",
    "    patch_size=32,\n",
    "    num_classes=2,\n",
    "    transformer=efficient_transformer,\n",
    "    channels=3,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ini"
    }
   },
   "outputs": [],
   "source": [
    "# loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "# scheduler这是个新东西叫做学习率调度器\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=gamma)\n",
    "\"\"\"\n",
    "StepLR：这是 PyTorch 中的一种学习率调度器。\n",
    "通过在每隔一定的训练周期（epoch）后衰减学习率来帮助模型更好地收敛。StepLR 通过“步长衰减”调整学习率。\n",
    "step_size=1：每过 step_size 个 epoch 后，学习率就会调整一次。在这个例子中，每训练 1 个 epoch 后学习率就会变化一次。\n",
    "gamma 是学习率衰减的系数，它控制每次调整学习率时衰减的比例。比如，gamma=0.1 表示每 step_size 个 epoch 后，学习率将减少为原来的 10%。\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ini"
    }
   },
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0#epoch_loss用来记录每个 epoch 的总损失\n",
    "    epoch_accuracy = 0#epoch_accuracy 用来记录每个 epoch 总准确率\n",
    "\n",
    "    for data, label in tqdm(train_loader):#tqdm 是一个进度条工具，显示训练进度\n",
    "        data = data.to(device)\n",
    "        label = label.to(device)#将数据和标签移动到 GPU\n",
    "\n",
    "        output = model(data)#将训练数据传入模型，得到模型的输出（预测值）。\n",
    "        loss = criterion(output, label)#使用预定义的损失函数（criterion）计算模型预测值和真实标签之间的差距。\n",
    "\n",
    "        \"\"\"这三板斧看着就觉得好方便啊~~~~\"\"\"\n",
    "        optimizer.zero_grad()#清除优化器之前的梯度信息。每次更新权重之前，都需要清除上一步计算的梯度。\n",
    "        loss.backward()#计算损失函数的梯度，这个梯度将用于调整模型的权重。\n",
    "        optimizer.step()#通过优化器更新模型的权重。\n",
    "\n",
    "        acc = (output.argmax(dim=1) == label).float().mean()#计算当前 batch 的准确率：\n",
    "                                                            #output.argmax(dim=1)：获取模型输出的最大值的索引，表示预测的类别。\n",
    "                                                            #== label：比较预测的类别和实际标签是否相同，返回一个布尔值（True 或 False）。\n",
    "                                                            #.float().mean()：将布尔值转换为浮点数（True = 1，False = 0），然后计算平均值(一个batch中各项的)，即准确率。\n",
    "        epoch_accuracy += acc / len(train_loader)#将当前 batch 的准确率加入到总准确率中，并且除以 len(train_loader)（总batch数）\n",
    "        epoch_loss += loss / len(train_loader)\n",
    "\n",
    "    with torch.no_grad():#验证阶段，禁用梯度计算\n",
    "        epoch_val_accuracy = 0\n",
    "        epoch_val_loss = 0#用来记录验证集的准确率和损失。\n",
    "\n",
    "        for data, label in valid_loader:#应该是验证花时间少点不用tqdm了\n",
    "            data = data.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            val_output = model(data)\n",
    "            val_loss = criterion(val_output, label)\n",
    "\n",
    "            acc = (val_output.argmax(dim=1) == label).float().mean()\n",
    "            epoch_val_accuracy += acc / len(valid_loader)\n",
    "            epoch_val_loss += val_loss / len(valid_loader)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch : {epoch+1} - loss : {epoch_loss:.4f} - acc: {epoch_accuracy:.4f} - val_loss : {epoch_val_loss:.4f} - val_acc: {epoch_val_accuracy:.4f}\\n\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
