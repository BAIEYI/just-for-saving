{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import glob\n",
    "from itertools import chain\n",
    "import os\n",
    "import random\n",
    "import zipfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from linformer import Linformer\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from module import ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training settings\n",
    "batch_size = 64\n",
    "epochs = 20\n",
    "lr = 3e-5\n",
    "gamma = 0.7\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('data', exist_ok=True)\n",
    "#创建一个名为 ‘data’ 的目录，如果它已经存在，就忽略这个操作，不要报错。\n",
    "train_dir = 'data/train'\n",
    "test_dir = 'data/test'\n",
    "\n",
    "with zipfile.ZipFile('train.zip') as train_zip:\n",
    "    #train_zip.extractall('data')#咋感觉这里应该是到train_dir呢。。。\n",
    "    train_zip.extractall(train_dir)#嗯，一定是大佬写错了\n",
    "    \n",
    "with zipfile.ZipFile('test.zip') as test_zip:\n",
    "    #test_zip.extractall('data')\n",
    "    test_zip.extractall(test_dir)\n",
    "\n",
    "train_list = glob.glob(os.path.join(train_dir,'*.jpg'))\n",
    "#在训练目录 train_dir 中查找所有 .jpg 文件，并将这些文件路径存储在 train_list 中。\n",
    "test_list = glob.glob(os.path.join(test_dir, '*.jpg'))\n",
    "#os.path.join 将 train_dir 和 *.jpg 拼接成一个完整路径。\n",
    "#*.jpg 是一个通配符，表示匹配所有以 .jpg 结尾的文件。\n",
    "#glob.glob会返回一个列表，包含目录中所有匹配指定模式的文件路径。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [path.split('/')[-1].split('.')[0] for path in train_list]\n",
    "#这行代码的作用是从 train_list 中的每个文件路径提取文件名，并且从文件名中提取去掉扩展名后的部分，最后将这些提取到的标签存储到一个名为 labels 的列表中。\n",
    "#path.split('/')这部分将 path 以 '/'（斜杠）作为分隔符拆分成多个子字符串，返回一个列表。如对于'data/train/image1.jpg'，返回 ['data', 'train', 'image1.jpg']\n",
    "#[-1] 选取拆分后的最后一个元素，即文件名和扩展名部分。\n",
    "#split('.')对文件名（如 'image1.jpg'）进行再次拆分,[0]选取拆分后的第一个部分，即文件名去掉扩展名的部分\n",
    "#最后执行完的labels也是一个列表，比如['image1', 'image2', 'image3']这样的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面这段代码可以去掉，顶多就是用于纠错的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "random_idx = np.random.randint(1, len(train_list), size=9)\n",
    "fig, axes = plt.subplots(3, 3, figsize=(16, 12))\n",
    "\n",
    "for idx, ax in enumerate(axes.ravel()):\n",
    "    img = Image.open(train_list[idx])\n",
    "    ax.set_title(labels[idx])\n",
    "    ax.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomResizedCrop(224),#随机裁剪图像的一部分，并将裁剪后的图像调整为 224x224 的大小\n",
    "        transforms.RandomHorizontalFlip(),# 随机水平翻转图像（数据增强）\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")#训练集的图像变换\n",
    "\n",
    "val_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),#中心裁剪，裁剪出 224x224 的部分\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")#验证集的图像变换\n",
    "\n",
    "\n",
    "test_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")#测试集的图像变换\n",
    "\n",
    "#我寻思要是自己试试的话，就验证集和测试集通用吧。。。。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "\n",
    "class CatsDogsDataset(Dataset):\n",
    "    def __init__(self, file_list, transform=None):\n",
    "        self.file_list = file_list\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        self.filelength = len(self.file_list)\n",
    "        return self.filelength#返回数据集中图像的总数\n",
    "\n",
    "    def __getitem__(self, idx):#获取指定索引的图像和标签\n",
    "        img_path = self.file_list[idx]#根据索引获取图像路径\n",
    "        img = Image.open(img_path)# 使用 PIL 打开图像\n",
    "        img_transformed = self.transform(img)#对图像进行变换（如果有的话）\n",
    "\n",
    "        label = img_path.split(\"/\")[-1].split(\".\")[0]\n",
    "        label = 1 if label == \"dog\" else 0# 如果是\"dog\"，标签为1，否则为0\n",
    "        \"\"\"这个label这看来还得根据数据集改改\"\"\"\n",
    "\n",
    "        return img_transformed, label# 返回变换后的图像和标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#每个数据集都通过 CatsDogsDataset 类进行创建\n",
    "train_data = CatsDogsDataset(train_list, transform=train_transforms)\n",
    "valid_data = CatsDogsDataset(valid_list, transform=test_transforms)\n",
    "test_data = CatsDogsDataset(test_list, transform=test_transforms)\n",
    "#通过 DataLoader 分别创建三个数据加载器\n",
    "train_loader = DataLoader(dataset = train_data, batch_size=batch_size, shuffle=True )\n",
    "valid_loader = DataLoader(dataset = valid_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset = test_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "#还是那个想法，感觉自己试试的话也就搞俩试试就行啊\n",
    "print(len(train_data), len(train_loader))\n",
    "print(len(valid_data), len(valid_loader))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
